{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "PATH = '../../ConsensusIO/dependencies/meta'\n",
    "with open(PATH, 'rb') as fp:\n",
    "    data_raw = pickle.load(fp)\n",
    "X, y = data_raw[\"X\"], data_raw[\"y\"]\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.pipeline import BaseEstimator, TransformerMixin, Pipeline\n",
    "import urlextract\n",
    "import re\n",
    "from html import unescape\n",
    "import string\n",
    "\n",
    "def html_to_plain_text(html: str) -> str:\n",
    "    from bs4 import BeautifulSoup\n",
    "    return BeautifulSoup(html, 'html.parser').get_text()\n",
    "def drop(s):\n",
    "    return re.sub(r'\\W+', ' ', s, flags=re.M)\n",
    "\n",
    "class Cleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include_subj=True, lower_case=True, stemming = True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True):\n",
    "        self.include_subj = include_subj\n",
    "        self.lower_case = lower_case\n",
    "        self.stemming = stemming\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_transformed = []\n",
    "        for article in X:\n",
    "            text = \" \".join(article) if self.include_subj else \" \".join(article[1:3])\n",
    "            text = html_to_plain_text(text)\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls:\n",
    "                url_extractor = urlextract.URLExtract() \n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', ' NUMBER ', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = text.replace(\"\\'\", \"\")\n",
    "                text = text.replace(\"â€™\", \"\")\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            if self.stemming:\n",
    "                stemmer = nltk.PorterStemmer()\n",
    "                text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "            X_transformed.append(text)\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'business insider a tesla analyst says he thinks model NUMBER us deliveries doubled in q NUMBER and the stock is surging tsla tesla shares rose NUMBER early monday as investors awaited second quarter delivery figures expected in the coming days and a bullish tesla analyst forecasted a sizeable jump in model NUMBER us deliveries the jmp securities analyst joseph osha said in a note to client ap photo rich pedroncelli tesla shares rose NUMBER early monday as investors awaited second quarter delivery figures expected in the coming days and a bullish tesla analyst forecasted a sizeable jump in model NUMBER us deliveries the jmp securities '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaner(stemming=False).fit_transform(X[:3])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1039: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "'''\n",
    "tf-idf frequency: \n",
    "\n",
    "tf: (total number of occurences of each word/total length of the document)\n",
    "keeps longer documents from being unjustly weighted\n",
    "\n",
    "idf: (1/ document frequency)\n",
    "downscale words that occur frequently in many documents as they are most likely useless\n",
    "\n",
    "tf-idf: tf*idf\n",
    "'''\n",
    "text_clf = Pipeline([\n",
    "    ('clean', Cleaner(stemming=False)), #cleans text\n",
    "    ('vect', CountVectorizer()), #turns words to counts \n",
    "    ('tfidf', TfidfTransformer()), #turns counts to tf-idf\n",
    "])\n",
    "X_prepared = text_clf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1233x9578 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 64365 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1233, 6795) (1233,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y_choice = y!=1\n",
    "print(X_prepared.shape, y_choice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1039: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808416418378885"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(LogisticRegression(solver=\"liblinear\", random_state=42, n_jobs=-1), X_prepared , y_choice, cv=10, verbose=0, scoring=\"accuracy\")\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
